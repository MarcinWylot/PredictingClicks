{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['express.no.transactions', 'express.total.spend','metro.no.transactions','metro.total.spend', \\\n",
    "             'superstore.no.transactions','superstore.total.spend','extra.no.transactions','extra.total.spend',\\\n",
    "             'fandf.no.transactions','fandf.total.spend','petrol.no.transactions','petrol.total.spend', \\\n",
    "             'direct.no.transactions','direct.total.spend']\n",
    "\n",
    "categorical = ['gender','affluency','county','content']\n",
    "\n",
    "data_file = 'data.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37347\n",
      "37347\n",
      "11205\n",
      "11205\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "import pandas\n",
    "\n",
    "random_state = 88 \n",
    "\n",
    "data = pandas.read_pickle(data_file)\n",
    "\n",
    "# for selecting model and it's basic parameters I use only a frantion of data \n",
    "# with only 10% of data for training it takes a few hours to execute so  I cannot affort more a.t.m.\n",
    "# an option here would be to donwsample negative classes (click == 0) to balance classes\n",
    "# however, I'll stick to stratified sampling \n",
    "for train_index, test_index in sklearn.model_selection.StratifiedShuffleSplit(n_splits=1, train_size=0.1, \\\n",
    "                                                        test_size=0.03, random_state=random_state).\\\n",
    "                                                        split(data, data['click']):\n",
    "    X_train = data[numerical+categorical].iloc[train_index]\n",
    "    y_train = data['click'].iloc[train_index]\n",
    "    \n",
    "    X_test = data[numerical+categorical].iloc[test_index]\n",
    "    y_test = data['click'].iloc[test_index]\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using modified methods from https://gist.github.com/miguelmalvarez/07e622357b089fee7f21\n",
    "import numpy\n",
    "import sklearn.preprocessing \n",
    "import sklearn.pipeline\n",
    "import sklearn.ensemble \n",
    "import sklearn.svm \n",
    "import sklearn.neighbors \n",
    "import sklearn.utils\n",
    "import sklearn.decomposition\n",
    "import xgboost \n",
    "import sklearn_pandas\n",
    "import prince\n",
    "\n",
    "\n",
    "def best_config(model_info, parameters, X_train, y_train):\n",
    "    [name, model] = model_info\n",
    "    print('Grid search for ', name)\n",
    "    # cv=5: integer, to specify the number of folds in a (Stratified)KFold\n",
    "    # roc_auc should be safe here for inbalanced classes\n",
    "    clf = sklearn.model_selection.GridSearchCV(model, parameters, cv=5, scoring=\"roc_auc\", n_jobs=-1, verbose=4)\n",
    "    %time clf.fit(X_train, y_train)\n",
    "    best_estimator = clf.best_estimator_\n",
    "    print('Best parameters: ', str(clf.best_params_))\n",
    "    print('scored: ', clf.best_score_)\n",
    " \n",
    "    return [str(clf.best_params_), clf.best_score_, best_estimator]\n",
    "\n",
    "def best_model(classifier_families, X_train, y_train):\n",
    "    best_score = 0.0\n",
    "    best_classifier = None    \n",
    "\n",
    "    for name, model, parameters in classifier_families:\n",
    "        classifier = best_config([name, model], parameters, X_train, y_train)\n",
    "        if (classifier[1] > best_score):\n",
    "            best_score = classifier[1]\n",
    "            best_classifier = [name, classifier]\n",
    "            \n",
    "    print('#'*150)\n",
    "    print('Best classifier: ', best_classifier[0])\n",
    "    print('scored: ', best_classifier[1][1])\n",
    "    print('with parameters: ', best_classifier[1][0])\n",
    "    return  best_classifier[1][2]\n",
    "\n",
    "\n",
    "# I focus on classical models for binary classyfication tuned with class_weight \n",
    "# an interesting would be to use anomaly detection models to detect positive classes (click == 1)\n",
    "# such as LOF, isolation forrest, or autoencoders\n",
    "def candidate_families(y_train):\n",
    "    candidates = []\n",
    "    svm_tuned_parameters = [{'kernel': ['linear', 'rbf'], \n",
    "                            'class_weight': ['balanced'], \n",
    "                            'C': numpy.linspace(1, 6, 3)}]\n",
    "    candidates.append([\"SVM\", \n",
    "                       sklearn.svm.SVC(gamma='scale', probability=True), \n",
    "                       svm_tuned_parameters])\n",
    "    \n",
    "    knn_tuned_parameters = [{'n_neighbors': [2,3,5,15,25]}]\n",
    "    candidates.append(['kNN', \n",
    "                       sklearn.neighbors.KNeighborsClassifier(), \n",
    "                       knn_tuned_parameters])\n",
    "    \n",
    "    rf_tuned_parameters = [{'n_estimators': [100, 200]}]\n",
    "    candidates.append(['RandomForest', \n",
    "                       sklearn.ensemble.RandomForestClassifier(class_weight='balanced'), \n",
    "                       rf_tuned_parameters])  \n",
    "                       \n",
    "    scale_pos_weight = y_train[y_train == 0].count() / y_train[y_train == 1].count()\n",
    "    xgb_tuned_parameters = [{'max_depth': [5,10,15], \n",
    "                             'n_estimators': [50, 100,200,300]}]\n",
    "    candidates.append(['XGBClassifier', \n",
    "                       xgboost.XGBClassifier(scale_pos_weight=scale_pos_weight),\n",
    "                       xgb_tuned_parameters])  \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaller(categorical,numerical):\n",
    "    \n",
    "    categorical_feature_def = sklearn_pandas.gen_features(\n",
    "        columns=[categorical],\n",
    "        classes=[{'class': prince.MCA, # I'm just playing with MCA, LabelBinarizer would be a standard choise \n",
    "                'n_components': 25, #this should be tuned\n",
    "                'n_iter': 5,\n",
    "                'engine': 'auto'}]\n",
    "    )\n",
    "\n",
    "    numerical_feature_def = [(numerical, sklearn.preprocessing.StandardScaler())]\n",
    "\n",
    "    mapper = sklearn_pandas.DataFrameMapper(categorical_feature_def+numerical_feature_def)\n",
    "\n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "mapper = feature_scaller(categorical,numerical)\n",
    "%time X_train_transformed = mapper.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for  SVM\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 118.0min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 278.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5h 38min 35s\n",
      "Best parameters:  {'C': 3.5, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "scored:  0.5995005723216651\n",
      "Grid search for  kNN\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed: 21.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed: 21.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 56s\n",
      "Best parameters:  {'n_neighbors': 25}\n",
      "scored:  0.5170691050604254\n",
      "Grid search for  RandomForest\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   40.6s remaining:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   51.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 11s\n",
      "Best parameters:  {'n_estimators': 200}\n",
      "scored:  0.6056348068626191\n",
      "Grid search for  XGBClassifier\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 3s\n",
      "Best parameters:  {'max_depth': 15, 'n_estimators': 300}\n",
      "scored:  0.6256088222379651\n",
      "######################################################################################################################################################\n",
      "Best classifier:  XGBClassifier\n",
      "scored:  0.6256088222379651\n",
      "with parameters:  {'max_depth': 15, 'n_estimators': 300}\n",
      "Wall time: 6h 16min 46s\n"
     ]
    }
   ],
   "source": [
    "%time best_classifier = best_model(candidate_families(y_train), X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 155 ms\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "%time X_test_transformed= mapper.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 534 ms\n",
      "Wall time: 465 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_test_pred = best_classifier.predict(X_test_transformed)\n",
    "%time y_test_proba = best_classifier.predict_proba(X_test_transformed)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     11061\n",
      "           1       0.12      0.01      0.01       144\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     11205\n",
      "   macro avg       0.56      0.50      0.50     11205\n",
      "weighted avg       0.98      0.99      0.98     11205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11054     7]\n",
      " [  143     1]]\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153175822961556"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(y_test, y_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031424745989432144"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(y_test, y_test_proba)\n",
    "sklearn.metrics.auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03393958376581965"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.average_precision_score(y_test, y_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006311590272127354"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.balanced_accuracy_score(y_test, y_test_pred, adjusted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011821106548702387"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.cohen_kappa_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297266    1\n",
       "338899    1\n",
       "47176     1\n",
       "261753    1\n",
       "198042    1\n",
       "167534    1\n",
       "246714    1\n",
       "314869    1\n",
       "18120     1\n",
       "166606    1\n",
       "350678    1\n",
       "335472    1\n",
       "367961    1\n",
       "248632    1\n",
       "137179    1\n",
       "73218     1\n",
       "230715    1\n",
       "312192    1\n",
       "326168    1\n",
       "246772    1\n",
       "29409     1\n",
       "191120    1\n",
       "260815    1\n",
       "250270    1\n",
       "246057    1\n",
       "201517    1\n",
       "46062     1\n",
       "272000    1\n",
       "257237    1\n",
       "281124    1\n",
       "         ..\n",
       "143991    1\n",
       "216061    1\n",
       "47833     1\n",
       "60839     1\n",
       "109243    1\n",
       "132661    1\n",
       "59249     1\n",
       "303449    1\n",
       "71919     1\n",
       "200374    1\n",
       "318102    1\n",
       "242929    1\n",
       "54545     1\n",
       "34091     1\n",
       "235539    1\n",
       "334580    1\n",
       "124781    1\n",
       "282700    1\n",
       "212415    1\n",
       "367702    1\n",
       "60098     1\n",
       "156134    1\n",
       "201436    1\n",
       "9520      1\n",
       "352295    1\n",
       "363955    1\n",
       "339629    1\n",
       "324346    1\n",
       "255663    1\n",
       "259278    1\n",
       "Name: click, Length: 144, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[y_test == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[y_test_pred == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
